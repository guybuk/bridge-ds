{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Preliminaries\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "from pathlib import Path\n",
    "\n",
    "import holoviews as hv\n",
    "import hvplot.pandas  # noqa\n",
    "import pandas as pd\n",
    "import panel as pn\n",
    "\n",
    "hv.extension(\"bokeh\")\n",
    "pn.extension()\n",
    "# If in google colab, run hack that allows holoviews to work properly\n",
    "try:\n",
    "    import google.colab  # noqa\n",
    "\n",
    "    def _render(self, **kwargs):\n",
    "        hv.extension(\"bokeh\")\n",
    "        return hv.Store.render(self)\n",
    "\n",
    "    hv.core.Dimensioned._repr_mimebundle_ = _render\n",
    "except ModuleNotFoundError:\n",
    "    pass\n",
    "\n",
    "TMP_NOTEBOOK_ROOT = Path(tempfile.mkdtemp()) / \"basics\" / \"coco_eda_demo\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Loading a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "To create BridgeDS Dataset objects, it's recommended to utilize a **DatasetProvider**. In this instance, we'll employ the Coco2017Detection provider:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bridge.display.vision import Holoviews\n",
    "from bridge.providers.vision import Coco2017Detection\n",
    "\n",
    "root_dir = TMP_NOTEBOOK_ROOT / \"coco\"\n",
    "\n",
    "provider = Coco2017Detection(root_dir)\n",
    "ds = provider.build_dataset()\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "# Real-life example: Exploratory Data Analysis on COCO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "In the previous tutorials we've made a brief introduction into using the Sample and Table APIs. In this demo we'll perform a short step-by-step analysis on COCO, using different toolings available in BridgeDS; emphasizing its ease of use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Assigning a column\n",
    "Let's take a brief look at our samples and annotations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.samples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.annotations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "In the annotations table, class names are represented by numerical labels, which may impede readability during dataset analysis. To address this, we may choose to use a third-party file that maps these integer labels to their corresponding text labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/amikelive/coco-labels/master/coco-labels-paper.txt\"\n",
    "\n",
    "classnames = urlopen(url).read().decode(\"utf-8\").splitlines()\n",
    "classnames = {i + 1: c for i, c in enumerate(classnames)}\n",
    "print(classnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "Like we've seen in the Table API tutorial, we can use `ds.assign_annotations` to replace our bounding box class labels with new ones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bridge.utils.data_objects import BoundingBox, ClassLabel\n",
    "\n",
    "\n",
    "def map_bbox_class_names(bbox, classnames):\n",
    "    coords = bbox.coords\n",
    "    class_idx = bbox.class_label.class_idx\n",
    "    class_name = classnames[class_idx]\n",
    "    return BoundingBox(coords, ClassLabel(class_idx, class_name))\n",
    "\n",
    "\n",
    "ds = ds.assign_annotations(\n",
    "    data=lambda samples, anns: anns.data.apply(lambda bbox: map_bbox_class_names(bbox, classnames))\n",
    ")\n",
    "ds.annotations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "Another issue is that  `ds.samples.date_captured` is actually made of strings, instead of pd.Timestamps. Let's fix that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ds.samples.date_captured.dtype)\n",
    "ds = ds.assign_samples(date_captured=lambda samples, anns: pd.to_datetime(samples.date_captured))\n",
    "print(ds.samples.date_captured.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "This is a short example of where the Table API shines. Most frameworks and libraries implement some variant of our Sample API, which in practice would mean that to do these assignement operations they would have to iterate through the dataset using a nested loop:\n",
    "\n",
    "```\n",
    "for sample in samples:\n",
    "    for annotation in samples:\n",
    "        <do...>\n",
    "```\n",
    "\n",
    "Which is both slow and verbose."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## Plotting some graphs\n",
    "With our dataframes now in appropriate formats, let's generate some basic plots to gain insights into our data.\n",
    "\n",
    "Note: While our preferred plotting API is [hvplot](https://hvplot.holoviz.org/), [Pandas Plotting](https://pandas.pydata.org/docs/user_guide/visualization.html) remains a viable option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = ds.annotations.data.apply(lambda bb: str(bb.class_label)).value_counts().hvplot.bar()\n",
    "\n",
    "plot.opts(\n",
    "    title=\"Class-histogram, COCO Train\",\n",
    "    width=900,\n",
    "    xrotation=90,\n",
    "    xlabel=\"class\",\n",
    "    ylabel=\"n_bboxes\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.samples.license.value_counts().hvplot.bar().opts(title=\"Image Licenses, Histogram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "(ds.samples.groupby(pd.Grouper(freq=\"d\", key=\"date_captured\")).size()).hvplot.bar().opts(\n",
    "    xrotation=45, title=\"Date Captured Histogram, COCO Train\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.annotations.area.hvplot.density().opts(\n",
    "    title=\"KDE of annotation area, COCO Train\",\n",
    "    xlabel=\"area (px)\",\n",
    "    ylabel=\"density\",\n",
    "    tools=[],\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "## Investigating a bbox with abnormally large area\n",
    "\n",
    "Observing the KDE plot, we notice an unnatural leftward squeezing. This behavior is likely due to `hvplot` setting the x-axis limits based on the minimum and maximum values present in the data. Could this suggest that one of our annotations has an area on the order of 8.0e+5 px^2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "large_ann = ds.annotations.loc[ds.annotations.area.idxmax()]\n",
    "large_ann"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "We can see the area of this annotation is 787151, so indeed in the order of 8.0e+5\n",
    "\n",
    "At this juncture, we've identified a specific sample with `id=400410` that warrants further examination. Utilizing the `ds.get` and `sample.show()` methods from the Sample API allows us to visualize this sample\n",
    "\n",
    "(Reminder: `ds.get` and `ds.iget` serve as equivalents to `df.loc` and `df.iloc`, respectively, _for single samples_)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_id = large_ann.name[0]  # MultiIndex loc causes the name to be tuples (<sample_id>,<element_id>)\n",
    "ds.get(sample_id).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "To gain a deeper understanding of the image and the size of the dining table annotation in question, we introduce DisplayEngines, which you've seen briefly in the Sample API tutorial. These objects are injected into Datasets  Samples, and Elements, enabling us to manipulate the behavior of the `ds.show() / sample.show / element.show()` methods.\n",
    "\n",
    "By default, the **SimplePrints** engine is utilized. Let's switch to the **Holoviews** engine for enhanced visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets are immutable, so we'll build a new dataset from the existing provider\n",
    "# with a new rendering engine, and then re-run the assignments we made.\n",
    "\n",
    "ds = provider.build_dataset(display_engine=Holoviews(bbox_format=\"xywh\"))\n",
    "ds = ds.assign_annotations(\n",
    "    data=lambda samples, anns: anns.data.apply(lambda bbox: map_bbox_class_names(bbox, classnames))\n",
    ")\n",
    "ds = ds.assign_samples(date_captured=lambda samples, anns: pd.to_datetime(samples.date_captured))\n",
    "\n",
    "ds.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "Now, we have a more user-friendly way to observe our data. You can freely scroll through using the slider and visualize different samples from the COCO, right in your notebook.\n",
    "\n",
    "Next up, let's visualize the specific sample (400410) that piqued our interest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.get(sample_id).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "## Sorting COCO dataset by bbox sizes\n",
    "Upon inspection, it's evident that the `dining table` annotation encompasses the entire image.\n",
    "\n",
    "To assess the frequency of such occurrences, let's render the samples in our dataset in descending order of annotation size.\n",
    "\n",
    "To achieve this:\n",
    "1. Assign a new column to `ds.samples` representing the area value of its largest annotation.\n",
    "2. Sort the samples by this column.\n",
    "3. Run `ds.show()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_largest_area_annotation_per_sample(samples, anns):\n",
    "    return (\n",
    "        anns.sort_values(\"area\", ascending=False)\n",
    "        .groupby(\"sample_id\")\n",
    "        .area.first()\n",
    "        .reindex(\n",
    "            samples.index.get_level_values(\"sample_id\")\n",
    "        )  # without reindex, the areas may have a different sample order than our `ds.samples` index\n",
    "        .values\n",
    "    )\n",
    "\n",
    "\n",
    "ds = ds.assign_samples(top_ann_area=get_largest_area_annotation_per_sample)\n",
    "ds.samples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.sort_samples(\"top_ann_area\", ascending=False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "By scrolling the slider, we observe images with very large annotations on the left, followed by images with very small annotations, and then images without annotations on the right."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "## Filtering out images with large bboxes\n",
    "An alternative approach is to remove samples with bounding boxes that cover the majority of the image. We can accomplish this using `ds.select_samples` and `ds.select_annotations`, which similarly to `ds.assign_samples` / `ds.assign_annotations`, work with a Pandas-like API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original dataset:\", ds)\n",
    "ds_smaller = ds.select_samples(lambda samples, anns: samples.top_ann_area < 1e5)\n",
    "print(\"Filtered dataset:\", ds_smaller)\n",
    "ds_smaller.sort_samples(\"top_ann_area\", ascending=False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "For completeness, let's plot the KDE from before on `ds_smaller`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_smaller.annotations.area.hvplot.density().opts(\n",
    "    title=\"KDE of annotation area, COCO Train\",\n",
    "    xlabel=\"area (px)\",\n",
    "    ylabel=\"density\",\n",
    "    tools=[],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "As we can see, there's still a leftward squeezing - although significantly less than before. We've gained some insight into the distribution of our bbox sizes, but there's always more to do. Feel free to change the bbox area threshold to something even smaller, or plot this KDE for individual classes (rather than all of them), etc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clean",
   "language": "python",
   "name": "clean"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
